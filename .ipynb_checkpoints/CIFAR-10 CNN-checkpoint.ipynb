{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CIFAR-10 Dataset\n",
    "CIFAR-10 consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. Here are the classes in the dataset, as well as 10 random images from each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niall\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 10)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# convert class vectors to binary vectors\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_test shape:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "X_val shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "img_size = 32\n",
    "img_channels = 3\n",
    "nb_classes = 10\n",
    "batch_size = 128\n",
    "epoch_max = 15\n",
    "drop_rate = 0.2\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, hist, plt_path):\n",
    "    score = model.evaluate(X_test_gray, Y_test, verbose=0)\n",
    "    print('Test loss: %.3f' % score[0])\n",
    "    print('Test accuracy: %.3f' % score[1])\n",
    "    plot_validation_history(hist, plt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model):\n",
    "    hist = model.fit(X_train, Y_train, \\\n",
    "                    batch_size=batch_size, \\\n",
    "                    nb_epoch=epoch_max, \\\n",
    "                    validation_data=(X_val_gray, Y_val), \\\n",
    "                    callbacks=[early_stop], \\\n",
    "                    shuffle=True, verbose=0)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: http://www.cs.nthu.edu.tw/~shwu/courses/ml/labs/11_NN_Regularization/11_NN_Regularization.html\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "model_cnn = Sequential()\n",
    "\n",
    "# convolutional hidden layers\n",
    "for i in range(6):\n",
    "    model_cnn.add(Convolution2D(32, 3, 3, \n",
    "                        input_shape=(img_size, img_size, img_channels), \n",
    "                        border_mode='same', activation='relu'))\n",
    "    \n",
    "    if (i + 1) % 2 == 0:\n",
    "        model_cnn.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "model_cnn.add(Dropout(drop_rate))\n",
    "    \n",
    "print('Output shape of last convolution layers: {0}'.format(model_cnn.output_shape))\n",
    "model_cnn.add(Flatten())\n",
    "\n",
    "# fully connected hidden layers\n",
    "for i in range(2):\n",
    "    model_cnn.add(Dense(512))\n",
    "    model_cnn.add(BatchNormalization(mode=1))\n",
    "    model_cnn.add(Activation('relu'))\n",
    "model_cnn.add(Dropout(drop_rate))\n",
    "\n",
    "# output layer\n",
    "model_cnn.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 302s 6ms/step - loss: 1.5908 - acc: 0.4306\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 316s 6ms/step - loss: 1.1079 - acc: 0.6046\n",
      "Epoch 3/15\n",
      "36096/50000 [====================>.........] - ETA: 1:26 - loss: 0.9566 - acc: 0.6609"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model_cnn.fit(x=X_train,y=Y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error percentage: 26.01%\n"
     ]
    }
   ],
   "source": [
    "scores = model_cnn.evaluate(X_test, Y_test, verbose = 0)\n",
    "print(\"Error percentage: %.2f%%\" %(100 - scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
